{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Web Crawling Prject 6\n",
    "## '대학교 커뮤니티 사이트 '에브리타임' 크롤링'\n",
    "- 대학교 커뮤니티 사이트인 '에브리타임'의 게시판에 있는 글을 크롤링\n",
    "- 분석을 위해 자유게시판의 text data 수집\n",
    "- Crawling 모듈로는 Selenium을 이용한다.\n",
    "- Webdriver는 Chrome을 이용한다.\n",
    "## 방법\n",
    "\n",
    "1. 에브리타임에 접속\n",
    "2. 로그인 및 자유게시판 접속\n",
    "3. 매 페이지마다 있는 게시글 크롤링\n",
    "4. 제목, 내용, 추천 수, 댓글 수, 시간, URL 등을 수집\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 가장 효율적인 방법\n",
    "- 먼저 각 게시글들의 URL을 크롤링한다.\n",
    "- 이후 URL을 이용해서 각 게시글에 접속한 후에 글 스크랩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. URL Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-01T18:31:03.062996Z",
     "start_time": "2018-12-01T18:31:03.038523Z"
    }
   },
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import time as t\n",
    "\n",
    "#options = webdriver.ChromeOptions()\n",
    "#options.add_argument('headless') \n",
    "#options.add_argument('window-size = 1920x1980')\n",
    "\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "driver.maximize_window()\n",
    "driver.get('https://everytime.kr')\n",
    "\n",
    "driver.find_element_by_class_name('login').find_element_by_link_text('로그인').click()\n",
    "\n",
    "driver.find_element_by_name('userid').send_keys('---------')\n",
    "driver.find_element_by_name('password').send_keys('-----------')\n",
    "\n",
    "driver.find_element_by_class_name('submit').click()\n",
    "\n",
    "driver.find_element_by_link_text('자유게시판').click()\n",
    "driver.refresh()\n",
    "\n",
    "URL_path = 'https://everytime.kr/377390/p/'\n",
    "\n",
    "URL_list = []\n",
    "i = 0\n",
    "error = 0\n",
    "\n",
    "while True:\n",
    "    \n",
    "    try:\n",
    "        URL = URL_path + str(i)\n",
    "        driver.get(URL)\n",
    "        driver.find_element_by_id('container')\n",
    "        try:\n",
    "            element = WebDriverWait(driver, 5).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, 'div.wrap.articles'))\n",
    "            )\n",
    "        except:\n",
    "            print('도저히 페이지 누루는 부분을 못 찾네')\n",
    "            drver.refresh()\n",
    "        \n",
    "        time.sleep(1)\n",
    "        driver.find_element_by_css_selector('div.wrap.articles')\n",
    "        for a in driver.find_elements_by_tag_name('article'):\n",
    "            URL_list.append(a.find_element_by_tag_name('a').get_attribute('href'))\n",
    "            \n",
    "        i += 1\n",
    "        \n",
    "        if i * 20 != len(URL_list):\n",
    "            i -= 1\n",
    "            \n",
    "    except:\n",
    "        print('Page is not loaded')\n",
    "        driver.refresh()\n",
    "        error += 1\n",
    "        if error == 20:\n",
    "            break\n",
    "            \n",
    "    print('\\r Working(%d/24000) and len of ULR_list = %d' %(i, len(URL_list)), end = '')\n",
    "    if i == 24000:\n",
    "        break\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(URL_list, columns = ['URL'])\n",
    "df.to_csv('everytimeURL{}.csv'.format(i), index = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43584"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('everytimeURL2182.csv', encoding = 'utf-8')\n",
    "URL_list = df['URL'].tolist()\n",
    "URL_list = list(set(URL_list))\n",
    "len(URL_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "driver.get('https://everytime.kr')\n",
    "\n",
    "driver.find_element_by_class_name('login').find_element_by_link_text('로그인').click()\n",
    "\n",
    "driver.find_element_by_name('userid').send_keys('----------')\n",
    "driver.find_element_by_name('password').send_keys('---------------')\n",
    "\n",
    "driver.find_element_by_class_name('submit').click()\n",
    "\n",
    "driver.find_element_by_link_text('자유게시판').click()\n",
    "driver.refresh()\n",
    "\n",
    "title_list = []\n",
    "content_list = []\n",
    "comment_list = []\n",
    "vote_list = []\n",
    "time_list = []\n",
    "error_url = []\n",
    "\n",
    "for i, url in enumerate(URL_list):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        driver.find_element_by_css_selector('div.wrap.articles')\n",
    "        \n",
    "        try:\n",
    "            element = WebDriverWait(driver, 5).until(\n",
    "                EC.presence_of_element_located((By.TAG_NAME, 'article'))\n",
    "            )\n",
    "        except:\n",
    "            print('No loading')\n",
    "            drver.refresh()\n",
    "            driver.get(URL_list[i])\n",
    "            error_url.append(i)\n",
    "            error += 1\n",
    "            if error > 100:\n",
    "                break\n",
    "        \n",
    "        title = driver.find_element_by_css_selector('h2.large').text\n",
    "        content = driver.find_element_by_css_selector('p.large').text\n",
    "        comment = driver.find_element_by_css_selector('ul.status li.comment').text\n",
    "        vote = driver.find_element_by_css_selector('ul.status li.vote').text\n",
    "        time = driver.find_element_by_css_selector('div.profile time').get_attribute('title')\n",
    "        \n",
    "        title_list.append(title)\n",
    "        content_list.append(content)\n",
    "        comment_list.append(comment)\n",
    "        vote_list.append(vote)\n",
    "        time_list.append(time)\n",
    "        \n",
    "        title_n = len(title_list)\n",
    "        content_n = len(content_list)\n",
    "        comment_n = len(comment_list)\n",
    "        vote_n = len(vote_list)\n",
    "        time_n = len(time_list)\n",
    "        \n",
    "        print('\\r Working(%d/43584), title:content:comment:vote:time = %d:%d:%d:%d:%d' %(i, title_n, content_n, comment_n, vote_n, time_n),\n",
    "              end = '')\n",
    "        \n",
    "        \n",
    "    except:\n",
    "        print('all error')\n",
    "        error_url.append(i)\n",
    "        driver.quit()\n",
    "        \n",
    "        driver = webdriver.Chrome()\n",
    "        driver.maximize_window()\n",
    "        driver.get('https://everytime.kr')\n",
    "        driver.find_element_by_class_name('login').find_element_by_link_text('로그인').click()\n",
    "        driver.find_element_by_name('userid').send_keys('---------')\n",
    "        driver.find_element_by_name('password').send_keys('-------------')\n",
    "        driver.find_element_by_class_name('submit').click()\n",
    "        driver.find_element_by_link_text('자유게시판').click()\n",
    "        driver.refresh()                \n",
    "        t.sleep(1)\n",
    "        \n",
    "        error += 1\n",
    "        if error > 100:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'title' : title_list, 'content' : content_list, 'comment' : comment_list, 'vote' : vote_list, 'time' : time_list}\n",
    "df = pd.DataFrame(data)\n",
    "df.to_pickle('everytime{}.pickle'.format(i))\n",
    "df.to_csv('everytime_final{}.csv'.format(i), index = False, encoding = 'utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 각 게시글 접속\n",
    "1. 각 게시글에 입장할 때 click을 통해 입장\n",
    "2. 각 게시글에 입장할 때 해당 게시글의 url을 통해 입장 << 이 방법 채택<br>\n",
    "(이유 : click을 이용하기 위해서는 window창을 각 게시글로 이동시켜줘야 함, scrolled into view, 번거로움)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time as t\n",
    "\n",
    "\n",
    "options = webdriver.Chromeoptions()\n",
    "options.add_argument('headless') \n",
    "options.add_argument('window-size = 1920x1980')\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "\n",
    "driver.get('https://everytime.kr')\n",
    "\n",
    "driver.find_element_by_class_name('login').find_element_by_link_text('로그인').click()\n",
    "\n",
    "driver.find_element_by_name('userid').send_keys('-------')\n",
    "driver.find_element_by_name('password').send_keys('--------')\n",
    "\n",
    "driver.find_element_by_class_name('submit').click()\n",
    "\n",
    "driver.find_element_by_link_text('자유게시판').click()\n",
    "driver.refresh()\n",
    "url = []\n",
    "time = []\n",
    "title = []\n",
    "content = []\n",
    "vote = []\n",
    "comment = []\n",
    "n = 0\n",
    "for page_number in range(1,501,1):\n",
    "    page_url = driver.current_url\n",
    "    driver.implicitly_wait(3)\n",
    "    driver.execute_script('window.scrollTo(0,document.body.scrollHeight);')\n",
    "    driver.execute_script('window.scrollTo(0,0);')\n",
    "    post_list = driver.find_elements_by_tag_name('article')\n",
    "    \n",
    "    for i in range(20):         \n",
    "        \n",
    "        \n",
    "        post_url = post_list[i].find_element_by_tag_name('a').get_attribute('href')\n",
    "        \n",
    "        #post_list[i].click()\n",
    "        #url.append(driver.current_url)\n",
    "        url.append(post_url)\n",
    "        time.append(driver.find_element_by_tag_name('time').get_attribute('title'))\n",
    "        \n",
    "        driver.get(post_url)\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html5lib')\n",
    "        print('start')\n",
    "        title.append(soup.select('h2.large')[0].text.strip())\n",
    "        print(i)\n",
    "        content.append(soup.select('p.large')[0].text.strip())\n",
    "        vote.append(soup.select('li.vote')[0].text.strip())\n",
    "        comment.append(soup.select('li.comment')[0].text.strip())\n",
    "        driver.back()\n",
    "        \n",
    "    if page_number % 50 == 0:\n",
    "        df = pd.DataFrame({'title' : title, 'content' : content, 'vote' : vote, 'comment' : comment, 'url' : url, 'time' : time})\n",
    "        df = df[['title', 'content', 'comment', 'vote', 'time', 'url']]\n",
    "        df.to_csv('everytime{}.csv'.format(page_number // 50))\n",
    "        url = []\n",
    "        time = []\n",
    "        title = []\n",
    "        content = []\n",
    "        vote = []\n",
    "        comment = []\n",
    "    driver.implicitly_wait(20)\n",
    "    driver.execute_script('window.scrollTo(0,document.body.scrollHeight);')\n",
    "    driver.find_element_by_css_selector('a.next').click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BeautifulSoup 파싱 없이 바로\n",
    "- driver에서 element로 바로 찾아서 append\n",
    "- 파싱으로 인해 페이지의 로드 시간이 소요되어 가끔 뒤에 코드가 먼저 실행되는 문제 해결\n",
    "- 시간 단축\n",
    "\n",
    "###  추가사항\n",
    "- 속도 개선을 위해 절대적 대기(sleep) -> 명시적 대기(explicit wait)로 변경\n",
    "- 속도 개선을 위해 chrome driver의 이미지 출력 옵션을 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time as t\n",
    "\n",
    "# 명시적 대기\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('headless')\n",
    "options.add_argument('window-size = 1920x1980')\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "\n",
    "driver.get('https://everytime.kr')\n",
    "\n",
    "driver.find_element_by_class_name('login').find_element_by_link_text('로그인').click()\n",
    "\n",
    "driver.find_element_by_name('userid').send_keys('------------')\n",
    "driver.find_element_by_name('password').send_keys('------------')\n",
    "\n",
    "driver.find_element_by_class_name('submit').click()\n",
    "\n",
    "driver.find_element_by_link_text('자유게시판').click()\n",
    "driver.refresh()\n",
    "\n",
    "url = []\n",
    "time = []\n",
    "title = []\n",
    "content = []\n",
    "vote = []\n",
    "comment = []\n",
    "n = 0\n",
    "\n",
    "#for page_number in range(1,501,1):\n",
    "for page_number in range(2):\n",
    "    page_url = driver.current_url\n",
    "\n",
    "    driver.execute_script('window.scrollTo(0,document.body.scrollHeight);')\n",
    "    driver.execute_script('window.scrollTo(0,0);')\n",
    "    t.sleep(1)\n",
    "    post_url_list = [u.get_attribute('href') for u in driver.find_elements_by_css_selector('article a.article')]\n",
    "    for i in range(3):\n",
    "        #post_list = driver.find_elements_by_tag_name('article')\n",
    "        #post_url = post_list[i].find_element_by_tag_name('a').get_attribute('href')\n",
    "        post_url = post_url_list[i]\n",
    "        #post_list[i].click()\n",
    "        driver.get(post_url)\n",
    "        \n",
    "        t.sleep(2)\n",
    "        url.append(post_url)\n",
    "        time.append(driver.find_element_by_tag_name('time').get_attribute('title'))\n",
    "\n",
    "\n",
    "        # method1\n",
    "        title.append(driver.find_element_by_css_selector('article a.article h2.large').text)\n",
    "\n",
    "        content.append(driver.find_element_by_css_selector('article a.article p.large').text.strip())\n",
    "        vote.append(driver.find_element_by_css_selector('article a.article ul.status li.vote').text)\n",
    "        comment.append(driver.find_element_by_css_selector('article a.article ul.status li.comment').text)\n",
    "\n",
    "        driver.back()\n",
    "        \n",
    "    if page_number % 50 == 0:\n",
    "        df = pd.DataFrame({'title' : title, 'content' : content, 'vote' : vote, 'comment' : comment, 'url' : url, 'time' : time})\n",
    "        df = df[['title', 'content', 'comment', 'vote', 'time', 'url']]\n",
    "        df.to_csv('everytime_data/everytime{}.csv'.format(page_number))\n",
    "        print(page_number)\n",
    "        title, content, vote, comment, url, time = [], [], [], [], [], []\n",
    "    driver.execute_script('window.scrollTo(0,document.body.scrollHeight);')\n",
    "    t.sleep(2)\n",
    "    driver.find_element_by_css_selector('a.next').click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 중간부터 시작\n",
    "- 여러 이유로 반복문이 중단되었을 때 이용\n",
    "- 마지막 page number을 입력해서 해당 페이지부터 재시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time as t\n",
    "\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('headless')\n",
    "options.add_argument('window-size = 1920x1980')\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "\n",
    "driver.get('https://everytime.kr')\n",
    "\n",
    "driver.find_element_by_class_name('login').find_element_by_link_text('로그인').click()\n",
    "\n",
    "driver.find_element_by_name('userid').send_keys('-----------')\n",
    "driver.find_element_by_name('password').send_keys('-------------')\n",
    "\n",
    "driver.find_element_by_class_name('submit').click()\n",
    "\n",
    "page_n = 46 # The page number to start\n",
    "driver.get('https://everytime.kr/377390/p/' + str(page_n))\n",
    "\n",
    "url = []\n",
    "time = []\n",
    "title = []\n",
    "content = []\n",
    "vote = []\n",
    "comment = []\n",
    "n = 0\n",
    "\n",
    "for page_number in range(page_n,2062,1):\n",
    "    \n",
    "    page_url = driver.current_url\n",
    "\n",
    "    driver.execute_script('window.scrollTo(0,document.body.scrollHeight);')\n",
    "    driver.execute_script('window.scrollTo(0,0);')\n",
    "    t.sleep(1)\n",
    "    post_url_list = [u.get_attribute('href') for u in driver.find_elements_by_css_selector('article a.article')]\n",
    "    for i in range(20):\n",
    "        #post_list = driver.find_elements_by_tag_name('article')\n",
    "        #post_url = post_list[i].find_element_by_tag_name('a').get_attribute('href')\n",
    "        post_url = post_url_list[i]\n",
    "        #post_list[i].click()\n",
    "        driver.get(post_url)\n",
    "        \n",
    "        t.sleep(2)\n",
    "        url.append(post_url)\n",
    "        time.append(driver.find_element_by_tag_name('time').get_attribute('title'))\n",
    "\n",
    "\n",
    "        # method1\n",
    "        title.append(driver.find_element_by_css_selector('article a.article h2.large').text)\n",
    "\n",
    "        content.append(driver.find_element_by_css_selector('article a.article p.large').text.strip())\n",
    "        vote.append(driver.find_element_by_css_selector('article a.article ul.status li.vote').text)\n",
    "        comment.append(driver.find_element_by_css_selector('article a.article ul.status li.comment').text)\n",
    "\n",
    "        driver.back()\n",
    "        \n",
    "    if page_number % 50 == 0:\n",
    "        df = pd.DataFrame({'title' : title, 'content' : content, 'vote' : vote, 'comment' : comment, 'url' : url, 'time' : time})\n",
    "        df = df[['title', 'content', 'comment', 'vote', 'time', 'url']]\n",
    "        df.to_csv('everytime_data/everytime{}.csv'.format(page_number))\n",
    "        print(page_number)\n",
    "        title, content, vote, comment, url, time = [], [], [], [], [], []\n",
    "    driver.execute_script('window.scrollTo(0,document.body.scrollHeight);')\n",
    "    t.sleep(2)\n",
    "    driver.find_element_by_css_selector('a.next').click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat csv files\n",
    "- 50page마다 저장했던 크롤링 데이터를 concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['everytime_data/clean_data\\\\everytime.csv', 'everytime_data/clean_data\\\\everytime100.csv', 'everytime_data/clean_data\\\\everytime150.csv', 'everytime_data/clean_data\\\\everytime200.csv', 'everytime_data/clean_data\\\\everytime240.csv', 'everytime_data/clean_data\\\\everytime250.csv', 'everytime_data/clean_data\\\\everytime300.csv', 'everytime_data/clean_data\\\\everytime350.csv', 'everytime_data/clean_data\\\\everytime400.csv', 'everytime_data/clean_data\\\\everytime425.csv', 'everytime_data/clean_data\\\\everytime450.csv', 'everytime_data/clean_data\\\\everytime46.csv', 'everytime_data/clean_data\\\\everytime50.csv', 'everytime_data/clean_data\\\\everytime500.csv', 'everytime_data/clean_data\\\\everytime550.csv', 'everytime_data/clean_data\\\\everytime570.csv', 'everytime_data/clean_data\\\\everytime600.csv', 'everytime_data/clean_data\\\\everytime650.csv', 'everytime_data/clean_data\\\\everytime700.csv'] \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12939 entries, 0 to 12938\n",
      "Data columns (total 6 columns):\n",
      "title      12939 non-null object\n",
      "content    12939 non-null object\n",
      "comment    12939 non-null int64\n",
      "vote       12939 non-null int64\n",
      "time       12939 non-null object\n",
      "url        12939 non-null object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 606.6+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>comment</th>\n",
       "      <th>vote</th>\n",
       "      <th>time</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>지하철에서 뭐 좀 쳐먹지마 제발</td>\n",
       "      <td>냄새 역겨워</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-11-01 12:56:28</td>\n",
       "      <td>https://everytime.kr/377390/v/56050760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>계절학기 수요 조사 신청 좀 도와주세요ㅠㅠ</td>\n",
       "      <td>중선인 교양이라 주관학과가 대양휴머니티칼리지인데요ㅠㅠㅠ 학교 홈페이지에 치니까 행정...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-11-01 12:55:30</td>\n",
       "      <td>https://everytime.kr/377390/v/56050712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>눈떠보니</td>\n",
       "      <td>11정거장이나 지나있네?</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-11-01 12:11:09</td>\n",
       "      <td>https://everytime.kr/377390/v/56048337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>휴게실에서 소리틀어놓고 스포츠중계보는건 뭐하자는거지</td>\n",
       "      <td>딴엔 소리 작게 틀어놨다고 생각하는모양인데 ㅋㅋ;</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-11-01 11:47:51</td>\n",
       "      <td>https://everytime.kr/377390/v/56046985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>와 방금기상</td>\n",
       "      <td>오늘 1교시부터 풀수업인데...\\r\\r\\r\\r\\r\\r\\r\\r\\r\\r\\r\\r\\n이참에...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-11-01 11:44:22</td>\n",
       "      <td>https://everytime.kr/377390/v/56046827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          title  \\\n",
       "0             지하철에서 뭐 좀 쳐먹지마 제발   \n",
       "1       계절학기 수요 조사 신청 좀 도와주세요ㅠㅠ   \n",
       "2                          눈떠보니   \n",
       "3  휴게실에서 소리틀어놓고 스포츠중계보는건 뭐하자는거지   \n",
       "4                        와 방금기상   \n",
       "\n",
       "                                             content  comment  vote  \\\n",
       "0                                             냄새 역겨워       16     0   \n",
       "1  중선인 교양이라 주관학과가 대양휴머니티칼리지인데요ㅠㅠㅠ 학교 홈페이지에 치니까 행정...        0     0   \n",
       "2                                      11정거장이나 지나있네?        8     0   \n",
       "3                        딴엔 소리 작게 틀어놨다고 생각하는모양인데 ㅋㅋ;        4     1   \n",
       "4  오늘 1교시부터 풀수업인데...\\r\\r\\r\\r\\r\\r\\r\\r\\r\\r\\r\\r\\n이참에...        5     1   \n",
       "\n",
       "                  time                                     url  \n",
       "0  2018-11-01 12:56:28  https://everytime.kr/377390/v/56050760  \n",
       "1  2018-11-01 12:55:30  https://everytime.kr/377390/v/56050712  \n",
       "2  2018-11-01 12:11:09  https://everytime.kr/377390/v/56048337  \n",
       "3  2018-11-01 11:47:51  https://everytime.kr/377390/v/56046985  \n",
       "4  2018-11-01 11:44:22  https://everytime.kr/377390/v/56046827  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "path = 'everytime_data/clean_data'\n",
    "all_files = glob.glob(path + '/*.csv')\n",
    "print(all_files, '\\n')\n",
    "df_list = [pd.read_csv(file, encoding = 'utf-8', index_col = None) for file in all_files]\n",
    "df = pd.concat(df_list)\n",
    "\n",
    "df.drop_duplicates('title', keep = 'first', inplace = True)\n",
    "df.reset_index(drop = True, inplace = True)\n",
    "df = df[['title', 'content', 'comment', 'vote', 'time', 'url']]\n",
    "\n",
    "df.to_csv('everytime_data/clean_data/everytime.csv', encoding = 'utf-8', index = False)\n",
    "print(df.info())\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
