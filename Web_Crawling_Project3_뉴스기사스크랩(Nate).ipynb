{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_name = pd.read_csv('company_names.csv', engine = 'python')\n",
    "company_name.loc[company_name['name'].str.contains('아모레')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('headless') \n",
    "options.add_argument('window-size = 1920x1980')\n",
    "\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "driver.get('https://news.nate.com')\n",
    "\n",
    "driver.find_element_by_id('input_search').send_keys('아모레퍼시픽')\n",
    "\n",
    "driver.find_element_by_id('acBtn').click()\n",
    "\n",
    "iframe = driver.find_element_by_id('contentsWraper').find_element_by_tag_name('iframe')\n",
    "driver.switch_to_frame(iframe)\n",
    "\n",
    "driver.find_element_by_css_selector('dl.option-list > dd.opt02 > span.sel02').click() # 검색영역 '제목' 선택\n",
    "\n",
    "# 기간 설정\n",
    "driver.find_element_by_name('ps1').clear()\n",
    "driver.find_element_by_name('ps1').send_keys('20100806')\n",
    "driver.find_element_by_name('ps2').clear()\n",
    "driver.find_element_by_name('ps2').send_keys('20180912')\n",
    "\n",
    "\n",
    "driver.find_element_by_class_name('type-search-btn').click()\n",
    "while True:\n",
    "    try:\n",
    "        if driver.find_element_by_css_selector('div.none-result'):\n",
    "            driver.refresh()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break\n",
    "time.sleep(1)\n",
    "\n",
    "test = 400\n",
    "url_list = []\n",
    "while True:\n",
    "    for i in range(test):\n",
    "        page_num = (i + 1)\n",
    "        \n",
    "        try:\n",
    "            titles = driver.find_elements_by_css_selector('dt.text-inline')\n",
    "            \n",
    "            if not titles:\n",
    "                iframe = driver.find_element_by_id('contentsWraper').find_element_by_tag_name('iframe')\n",
    "                driver.switch_to_frame(iframe)\n",
    "                titles = driver.find_elements_by_css_selector('dt.text-inline')\n",
    "            for j in range(len(titles)):\n",
    "                #print(titles[j].find_element_by_tag_name('a').get_attribute('href'))\n",
    "                url_list.append(titles[j].find_element_by_tag_name('a').get_attribute('href'))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print('이번 페이지는 크롤링 못 했다. (%d페이지)' %page_num)\n",
    "            \n",
    "        if i % 100 == 0:\n",
    "            print('진행상황 ({}/400)'.format(i))\n",
    "            pd.Series(url_list).to_csv('news_data/news{}.csv'.format(i), index = False)\n",
    "            url_list = []\n",
    "        if i == (test-1):\n",
    "            break\n",
    "        driver.find_element_by_css_selector('.section.news.last > div.paging').find_element_by_link_text('다음').click()\n",
    "        time.sleep(1)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# url로 접근\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('headless') \n",
    "options.add_argument('window-size = 1920x1980')\n",
    "\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "driver.get('https://news.nate.com')\n",
    "\n",
    "driver.find_element_by_id('input_search').send_keys('아모레퍼시픽')\n",
    "\n",
    "driver.find_element_by_id('acBtn').click()\n",
    "\n",
    "iframe = driver.find_element_by_id('contentsWraper').find_element_by_tag_name('iframe')\n",
    "driver.switch_to_frame(iframe)\n",
    "\n",
    "#driver.find_element_by_css_selector('dl.option-list > dd.opt02 > span.sel02').click() # 검색영역 '제목' 선택\n",
    "\n",
    "# 기간 설정\n",
    "driver.find_element_by_name('ps1').clear()\n",
    "driver.find_element_by_name('ps1').send_keys('20100806')\n",
    "driver.find_element_by_name('ps2').clear()\n",
    "driver.find_element_by_name('ps2').send_keys('20180912')\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "driver.find_element_by_class_name('type-search-btn').click()\n",
    "justin = 0\n",
    "while True:\n",
    "    try:\n",
    "        if driver.find_element_by_css_selector('div.none-result'):\n",
    "            driver.refresh()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break\n",
    "time.sleep(1)\n",
    "\n",
    "lastdate = datetime.datetime.strptime('20180912', '%Y%m%d')\n",
    "url_list = []\n",
    "p = 20\n",
    "while True:\n",
    "    print('jjjjjjjjjjjjj : ', justin)\n",
    "    print('While문 진입')\n",
    "    try:\n",
    "        #if driver.find_element_by_id('contentsWraper').find_element_by_tag_name('iframe'):\n",
    "        iframe = driver.find_element_by_id('contentsWraper').find_element_by_tag_name('iframe')\n",
    "        driver.switch_to_frame(iframe)\n",
    "        page_url = driver.find_element_by_css_selector('div.paging > span > a').get_attribute('href')\n",
    "        page_url = page_url[:-2]\n",
    "        for i in range(p):\n",
    "            try:\n",
    "                URL = page_url + str(1 + (i * 10))\n",
    "                driver.get(URL)\n",
    "                time.sleep(1)\n",
    "                titles = driver.find_elements_by_css_selector('dt.text-inline')\n",
    "                \n",
    "                if p > 10:\n",
    "                    print(i, '   이건데 왜 이거 실행함?')\n",
    "                    dates = [day.text[-16:-6].replace('.', '') for day in driver.find_elements_by_css_selector('ul.search-list dl dd.text-inline span')]\n",
    "                    dtime = [datetime.datetime.strptime(d, '%Y%m%d') for d in dates]\n",
    "                    if lastdate > min(dtime):\n",
    "                        lastdate = min(dtime)\n",
    "                    print(lastdate + '   *' * 100)                \n",
    "                \n",
    "                for j in range(len(titles)):\n",
    "                    url_list.append(titles[j].find_element_by_tag_name('a').get_attribute('href').replace('https://news.nate.com/view/', ''))\n",
    "                if i == 99:\n",
    "                    print('진행상황 ({}/99)'.format(i + justin*100))\n",
    "                    pd.Series(url_list).to_csv('news_data/news{}.csv'.format(i + justin * 100), index = False)\n",
    "                    url_list = []\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print('이번 페이지는 크롤링 못 했다. (%d페이지)' %(i+1))\n",
    "                URL = page_url + str(1 + (i * 10))\n",
    "                driver.get(URL)\n",
    "                time.sleep(1)\n",
    "                titles = driver.find_elements_by_css_selector('dt.text-inline')\n",
    "                \n",
    "                if p > 10:\n",
    "                    print(i, '   이건데 왜 이거 실행함?')                    \n",
    "                    dates = [day.text[-16:-6].replace('.', '') for day in driver.find_elements_by_css_selector('ul.search-list dl dd.text-inline span')]\n",
    "                    dtime = [datetime.datetime.strptime(d, '%Y%m%d') for d in dates]\n",
    "                    if lastdate > min(dtime):\n",
    "                        lastdate = min(dtime)\n",
    "                    print(lastdate + '   *' * 100)\n",
    "                    \n",
    "                for j in range(len(titles)):\n",
    "                    url_list.append(titles[j].find_element_by_tag_name('a').get_attribute('href').replace('https://news.nate.com/view/', ''))\n",
    "                if i == 99:\n",
    "                    print('진행상황 ({}/99)'.format(i + justin * 100))\n",
    "                    pd.Series(url_list).to_csv('news_data/news{}.csv'.format(i + justin * 100), index = False)\n",
    "                    url_list = []\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('No iframe')\n",
    "        #iframe = driver.find_element_by_id('contentsWraper').find_element_by_tag_name('iframe')\n",
    "        #driver.switch_to_frame(iframe)\n",
    "        page_url = driver.find_element_by_css_selector('div.paging > span > a').get_attribute('href')\n",
    "        page_url = page_url[:-2]\n",
    "        for i in range(p):\n",
    "            try:\n",
    "                print(i,' *' * 100)\n",
    "                URL = page_url + str(1 + (i * 10))\n",
    "                driver.get(URL)\n",
    "                time.sleep(1)\n",
    "                titles = driver.find_elements_by_css_selector('dt.text-inline')\n",
    "                \n",
    "                if p > 10:                \n",
    "                    dates = [day.text[-16:-6].replace('.', '') for day in driver.find_elements_by_css_selector('ul.search-list dl dd.text-inline span')]\n",
    "                    dtime = [datetime.datetime.strptime(d, '%Y%m%d') for d in dates]\n",
    "                    if lastdate > min(dtime):\n",
    "                        lastdate = min(dtime)\n",
    "                    print(lastdate, '   *' * 100)                \n",
    "                \n",
    "                for j in range(len(titles)):\n",
    "                    url_list.append(titles[j].find_element_by_tag_name('a').get_attribute('href').replace('https://news.nate.com/view/', ''))\n",
    "                if  i == 99:\n",
    "                    print('진행상황 ({}/99)'.format(i + justin * 100))\n",
    "                    pd.Series(url_list).to_csv('news_data/news{}.csv'.format(i + justin*100), index = False)\n",
    "                    url_list = []\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(i,' * ' * 100)                \n",
    "                print(e)\n",
    "                print('이번 페이지는 크롤링 못 했다. (%d페이지)' %(i+1))\n",
    "                URL = page_url + str(1 + (i * 10))\n",
    "                driver.get(URL)\n",
    "                time.sleep(1)\n",
    "                titles = driver.find_elements_by_css_selector('dt.text-inline')\n",
    "                \n",
    "                if p > 10:                \n",
    "                    dates = [day.text[-16:-6].replace('.', '') for day in driver.find_elements_by_css_selector('ul.search-list dl dd.text-inline span')]\n",
    "                    dtime = [datetime.datetime.strptime(d, '%Y%m%d') for d in dates]\n",
    "                    if lastdate > min(dtime):\n",
    "                        lastdate = min(dtime)\n",
    "                    print(lastdate, '   *' * 100)                \n",
    "                \n",
    "                for j in range(len(titles)):\n",
    "                    url_list.append(titles[j].find_element_by_tag_name('a').get_attribute('href').replace('https://news.nate.com/view/', ''))\n",
    "                if  i == 99:\n",
    "                    print('진행상황 ({}/99)'.format(i + justin * 100))\n",
    "                    pd.Series(url_list).to_csv('news_data/news{}.csv'.format(i + justin * 100), index = False)\n",
    "                    url_list = []\n",
    "        \n",
    "    # 마지막 페이지의 마지막 글의 날짜\n",
    "    #date_list = driver.find_elements_by_css_selector('ul.search-list dl dd.text-inline span')\n",
    "    #date = date_list[9].text[-16:-6].replace('.', '')\n",
    "    \n",
    "    dateinput = lastdate.strftime('%Y%m%d')\n",
    "    driver.find_element_by_name('ps1').clear()\n",
    "    driver.find_element_by_name('ps1').send_keys('20100806')\n",
    "    driver.find_element_by_name('ps2').clear()\n",
    "    driver.find_element_by_name('ps2').send_keys(dateinput)\n",
    "    time.sleep(2)\n",
    "    print(dateinput)\n",
    "    #driver.find_element_by_css_selector('dl.option-list > dd.opt02 > span.sel02').click() # 검색영역 '제목' 선택\n",
    "    driver.find_element_by_class_name('type-search-btn').click()\n",
    "    print('endendendendenden : ', justin)\n",
    "    justin = justin + 1\n",
    "    if justin == 123:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url로 접근\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('headless') \n",
    "options.add_argument('window-size = 1920x1980')\n",
    "\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "driver.get('https://news.nate.com')\n",
    "\n",
    "driver.find_element_by_id('input_search').send_keys('아모레퍼시픽')\n",
    "\n",
    "driver.find_element_by_id('acBtn').click()\n",
    "\n",
    "iframe = driver.find_element_by_id('contentsWraper').find_element_by_tag_name('iframe')\n",
    "driver.switch_to_frame(iframe)\n",
    "\n",
    "#driver.find_element_by_css_selector('dl.option-list > dd.opt02 > span.sel02').click() # 검색영역 '제목' 선택\n",
    "\n",
    "# 기간 설정\n",
    "driver.find_element_by_name('ps1').clear()\n",
    "driver.find_element_by_name('ps1').send_keys('20100806')\n",
    "driver.find_element_by_name('ps2').clear()\n",
    "driver.find_element_by_name('ps2').send_keys('20180912')\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "driver.find_element_by_class_name('type-search-btn').click()\n",
    "justin = 0\n",
    "while True:\n",
    "    try:\n",
    "        if driver.find_element_by_css_selector('div.none-result'):\n",
    "            driver.refresh()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break\n",
    "time.sleep(1)\n",
    "\n",
    "lastdate = datetime.datetime.strptime('20180912', '%Y%m%d')\n",
    "url_list = []\n",
    "p = 20\n",
    "while True:\n",
    "    print('jjjjjjjjjjjjj : ', justin)\n",
    "    print('While문 진입')\n",
    "    try:\n",
    "        #if driver.find_element_by_id('contentsWraper').find_element_by_tag_name('iframe'):\n",
    "        iframe = driver.find_element_by_id('contentsWraper').find_element_by_tag_name('iframe')\n",
    "        driver.switch_to_frame(iframe)\n",
    "        page_url = driver.find_element_by_css_selector('div.paging > span > a').get_attribute('href')\n",
    "        page_url = page_url[:-2]\n",
    "        for i in range(p):\n",
    "            try:\n",
    "                URL = page_url + str(1 + (i * 10))\n",
    "                driver.get(URL)\n",
    "                time.sleep(1)\n",
    "                titles = driver.find_elements_by_css_selector('dt.text-inline')\n",
    "                \n",
    "                if p > 10:\n",
    "                    print(i, '   이건데 왜 이거 실행함?')\n",
    "                    dates = [day.text[-16:-6].replace('.', '') for day in driver.find_elements_by_css_selector('ul.search-list dl dd.text-inline span')]\n",
    "                    dtime = [datetime.datetime.strptime(d, '%Y%m%d') for d in dates]\n",
    "                    if lastdate > min(dtime):\n",
    "                        lastdate = min(dtime)\n",
    "                    print(lastdate + '   *' * 100)                \n",
    "                \n",
    "                for j in range(len(titles)):\n",
    "                    url_list.append(titles[j].find_element_by_tag_name('a').get_attribute('href').replace('https://news.nate.com/view/', ''))\n",
    "                if i == 99:\n",
    "                    print('진행상황 ({}/99)'.format(i + justin*100))\n",
    "                    pd.Series(url_list).to_csv('news_data/news{}.csv'.format(i + justin * 100), index = False)\n",
    "                    url_list = []\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print('이번 페이지는 크롤링 못 했다. (%d페이지)' %(i+1))\n",
    "                URL = page_url + str(1 + (i * 10))\n",
    "                driver.get(URL)\n",
    "                time.sleep(1)\n",
    "                titles = driver.find_elements_by_css_selector('dt.text-inline')\n",
    "                \n",
    "                if p > 10:\n",
    "                    print(i, '   이건데 왜 이거 실행함?')                    \n",
    "                    dates = [day.text[-16:-6].replace('.', '') for day in driver.find_elements_by_css_selector('ul.search-list dl dd.text-inline span')]\n",
    "                    dtime = [datetime.datetime.strptime(d, '%Y%m%d') for d in dates]\n",
    "                    if lastdate > min(dtime):\n",
    "                        lastdate = min(dtime)\n",
    "                    print(lastdate + '   *' * 100)\n",
    "                    \n",
    "                for j in range(len(titles)):\n",
    "                    url_list.append(titles[j].find_element_by_tag_name('a').get_attribute('href').replace('https://news.nate.com/view/', ''))\n",
    "                if i == 99:\n",
    "                    print('진행상황 ({}/99)'.format(i + justin * 100))\n",
    "                    pd.Series(url_list).to_csv('news_data/news{}.csv'.format(i + justin * 100), index = False)\n",
    "                    url_list = []\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('No iframe')\n",
    "        #iframe = driver.find_element_by_id('contentsWraper').find_element_by_tag_name('iframe')\n",
    "        #driver.switch_to_frame(iframe)\n",
    "        page_url = driver.find_element_by_css_selector('div.paging > span > a').get_attribute('href')\n",
    "        page_url = page_url[:-2]\n",
    "        for i in range(p):\n",
    "            try:\n",
    "                print(i,' *' * 100)\n",
    "                URL = page_url + str(1 + (i * 10))\n",
    "                driver.get(URL)\n",
    "                time.sleep(1)\n",
    "                titles = driver.find_elements_by_css_selector('dt.text-inline')\n",
    "                \n",
    "                if p > 10:                \n",
    "                    dates = [day.text[-16:-6].replace('.', '') for day in driver.find_elements_by_css_selector('ul.search-list dl dd.text-inline span')]\n",
    "                    dtime = [datetime.datetime.strptime(d, '%Y%m%d') for d in dates]\n",
    "                    if lastdate > min(dtime):\n",
    "                        lastdate = min(dtime)\n",
    "                    print(lastdate, '   *' * 100)                \n",
    "                \n",
    "                for j in range(len(titles)):\n",
    "                    url_list.append(titles[j].find_element_by_tag_name('a').get_attribute('href').replace('https://news.nate.com/view/', ''))\n",
    "                if  i == 99:\n",
    "                    print('진행상황 ({}/99)'.format(i + justin * 100))\n",
    "                    pd.Series(url_list).to_csv('news_data/news{}.csv'.format(i + justin*100), index = False)\n",
    "                    url_list = []\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(i,' * ' * 100)                \n",
    "                print(e)\n",
    "                print('이번 페이지는 크롤링 못 했다. (%d페이지)' %(i+1))\n",
    "                URL = page_url + str(1 + (i * 10))\n",
    "                driver.get(URL)\n",
    "                time.sleep(1)\n",
    "                titles = driver.find_elements_by_css_selector('dt.text-inline')\n",
    "                \n",
    "                if p > 10:                \n",
    "                    dates = [day.text[-16:-6].replace('.', '') for day in driver.find_elements_by_css_selector('ul.search-list dl dd.text-inline span')]\n",
    "                    dtime = [datetime.datetime.strptime(d, '%Y%m%d') for d in dates]\n",
    "                    if lastdate > min(dtime):\n",
    "                        lastdate = min(dtime)\n",
    "                    print(lastdate, '   *' * 100)                \n",
    "                \n",
    "                for j in range(len(titles)):\n",
    "                    url_list.append(titles[j].find_element_by_tag_name('a').get_attribute('href').replace('https://news.nate.com/view/', ''))\n",
    "                if  i == 99:\n",
    "                    print('진행상황 ({}/99)'.format(i + justin * 100))\n",
    "                    pd.Series(url_list).to_csv('news_data/news{}.csv'.format(i + justin * 100), index = False)\n",
    "                    url_list = []\n",
    "        \n",
    "    # 마지막 페이지의 마지막 글의 날짜\n",
    "    #date_list = driver.find_elements_by_css_selector('ul.search-list dl dd.text-inline span')\n",
    "    #date = date_list[9].text[-16:-6].replace('.', '')\n",
    "    \n",
    "    dateinput = lastdate.strftime('%Y%m%d')\n",
    "    driver.find_element_by_name('ps1').clear()\n",
    "    driver.find_element_by_name('ps1').send_keys('20100806')\n",
    "    driver.find_element_by_name('ps2').clear()\n",
    "    driver.find_element_by_name('ps2').send_keys(dateinput)\n",
    "    time.sleep(2)\n",
    "    print(dateinput)\n",
    "    #driver.find_element_by_css_selector('dl.option-list > dd.opt02 > span.sel02').click() # 검색영역 '제목' 선택\n",
    "    driver.find_element_by_class_name('type-search-btn').click()\n",
    "    print('endendendendenden : ', justin)\n",
    "    justin = justin + 1\n",
    "    if justin == 123:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 두 Try를 하나로 줄여보자.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url로 접근\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('headless') \n",
    "options.add_argument('window-size = 1920x1980')\n",
    "\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "driver.get('https://news.nate.com')\n",
    "\n",
    "driver.find_element_by_id('input_search').send_keys('아모레퍼시픽')\n",
    "\n",
    "driver.find_element_by_id('acBtn').click()\n",
    "\n",
    "iframe = driver.find_element_by_id('contentsWraper').find_element_by_tag_name('iframe')\n",
    "driver.switch_to_frame(iframe)\n",
    "\n",
    "#driver.find_element_by_css_selector('dl.option-list > dd.opt02 > span.sel02').click() # 검색영역 '제목' 선택\n",
    "\n",
    "# 기간 설정\n",
    "driver.find_element_by_name('ps1').clear()\n",
    "driver.find_element_by_name('ps1').send_keys('20100806')\n",
    "driver.find_element_by_name('ps2').clear()\n",
    "driver.find_element_by_name('ps2').send_keys('20180912')\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "driver.find_element_by_class_name('type-search-btn').click()\n",
    "justin = 0\n",
    "while True:\n",
    "    try:\n",
    "        if driver.find_element_by_css_selector('div.none-result'):\n",
    "            driver.refresh()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break\n",
    "time.sleep(1)\n",
    "\n",
    "lastdate = datetime.datetime.strptime('20180912', '%Y%m%d')\n",
    "url_list = []\n",
    "p = 20\n",
    "\n",
    "while True:\n",
    "    print('jjjjjjjjjjjjj : ', justin)\n",
    "    print('While문 진입')\n",
    "    try:\n",
    "        #driver.find_element_by_id('contentsWraper').find_element_by_tag_name('iframe')\n",
    "        #iframe = driver.find_element_by_id('contentsWraper').find_element_by_tag_name('iframe')\n",
    "        #driver.switch_to_frame(iframe)\n",
    "        page_url = driver.find_element_by_css_selector('div.paging > span > a').get_attribute('href')\n",
    "        page_url = page_url[:-2]\n",
    "        for i in range(p):\n",
    "            try:\n",
    "                URL = page_url + str(1 + (i * 10))\n",
    "                driver.get(URL)\n",
    "                time.sleep(1)\n",
    "                titles = driver.find_elements_by_css_selector('dt.text-inline')\n",
    "                \n",
    "                if p > 10:\n",
    "                    print(i, '   이건데 왜 이거 실행함?')\n",
    "                    dates = [day.text[-16:-6].replace('.', '') for day in driver.find_elements_by_css_selector('ul.search-list dl dd.text-inline span')]\n",
    "                    dtime = [datetime.datetime.strptime(d, '%Y%m%d') for d in dates]\n",
    "                    if lastdate > min(dtime):\n",
    "                        lastdate = min(dtime)\n",
    "                    print(lastdate + '   *' * 100)                \n",
    "                \n",
    "                for j in range(len(titles)):\n",
    "                    url_list.append(titles[j].find_element_by_tag_name('a').get_attribute('href').replace('https://news.nate.com/view/', ''))\n",
    "                if i == 99:\n",
    "                    print('진행상황 ({}/99)'.format(i + justin*100))\n",
    "                    pd.Series(url_list).to_csv('news_data/news{}.csv'.format(i + justin * 100), index = False)\n",
    "                    url_list = []\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print('이번 페이지는 크롤링 못 했다. (%d페이지)' %(i+1))\n",
    "                URL = page_url + str(1 + (i * 10))\n",
    "                driver.get(URL)\n",
    "                time.sleep(1)\n",
    "                titles = driver.find_elements_by_css_selector('dt.text-inline')\n",
    "                \n",
    "                if p > 10:\n",
    "                    print(i, '   이건데 왜 이거 실행함?')                    \n",
    "                    dates = [day.text[-16:-6].replace('.', '') for day in driver.find_elements_by_css_selector('ul.search-list dl dd.text-inline span')]\n",
    "                    dtime = [datetime.datetime.strptime(d, '%Y%m%d') for d in dates]\n",
    "                    if lastdate > min(dtime):\n",
    "                        lastdate = min(dtime)\n",
    "                    print(lastdate + '   *' * 100)\n",
    "                    \n",
    "                for j in range(len(titles)):\n",
    "                    url_list.append(titles[j].find_element_by_tag_name('a').get_attribute('href').replace('https://news.nate.com/view/', ''))\n",
    "                if i == 99:\n",
    "                    print('진행상황 ({}/99)'.format(i + justin * 100))\n",
    "                    pd.Series(url_list).to_csv('news_data/news{}.csv'.format(i + justin * 100), index = False)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    dateinput = lastdate.strftime('%Y%m%d')\n",
    "    driver.find_element_by_name('ps1').clear()\n",
    "    driver.find_element_by_name('ps1').send_keys('20100806')\n",
    "    driver.find_element_by_name('ps2').clear()\n",
    "    driver.find_element_by_name('ps2').send_keys(dateinput)\n",
    "    time.sleep(2)\n",
    "    print(dateinput)\n",
    "    #driver.find_element_by_css_selector('dl.option-list > dd.opt02 > span.sel02').click() # 검색영역 '제목' 선택\n",
    "    driver.find_element_by_class_name('type-search-btn').click()\n",
    "    print('endendendendenden : ', justin)\n",
    "    justin = justin + 1\n",
    "    if justin == 123:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [day.text[-16:-6].replace('.', '') for day in driver.find_elements_by_css_selector('ul.search-list dl dd.text-inline span')]\n",
    "dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 새로 도전(성공!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# url로 접근\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('headless') \n",
    "options.add_argument('window-size = 1920x1980')\n",
    "\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "driver.get('https://news.nate.com')\n",
    "\n",
    "driver.find_element_by_id('input_search').send_keys('아모레퍼시픽')\n",
    "\n",
    "driver.find_element_by_id('acBtn').click()\n",
    "\n",
    "iframe = driver.find_element_by_id('contentsWraper').find_element_by_tag_name('iframe')\n",
    "driver.switch_to_frame(iframe)\n",
    "\n",
    "#driver.find_element_by_css_selector('dl.option-list > dd.opt02 > span.sel02').click() # 검색영역 '제목' 선택\n",
    "\n",
    "# 기간 설정\n",
    "driver.find_element_by_name('ps1').clear()\n",
    "driver.find_element_by_name('ps1').send_keys('20100806')\n",
    "driver.find_element_by_name('ps2').clear()\n",
    "driver.find_element_by_name('ps2').send_keys('20180912')\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "driver.find_element_by_class_name('type-search-btn').click()\n",
    "time.sleep(5)\n",
    "\n",
    "justin = 0\n",
    "start_date = '20180912'\n",
    "finish_date = '20100806'\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        if driver.find_element_by_css_selector('div.none-result'):\n",
    "            driver.refresh()\n",
    "            time.sleep(3)\n",
    "            print('검색 클릭 후 창 출력 실패 -> refresh')\n",
    "            ### 여기가 문제구먼 날짜가 바뀌는 부분\n",
    "            driver.find_element_by_name('ps1').clear()\n",
    "            driver.find_element_by_name('ps1').send_keys(finish_date)\n",
    "            driver.find_element_by_name('ps2').clear()\n",
    "            driver.find_element_by_name('ps2').send_keys(start_date)\n",
    "            driver.find_element_by_class_name('type-search-btn').click()\n",
    "    except Exception as e:\n",
    "        print('페이지가 정상적으로 출력')\n",
    "        break\n",
    "time.sleep(1)\n",
    "\n",
    "stop = 0\n",
    "while True:\n",
    "    try:\n",
    "        iframe = driver.find_element_by_id('contentsWraper').find_element_by_tag_name('iframe')\n",
    "        driver.switch_to_frame(iframe)\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print('iframe이 이미 있습니다.')\n",
    "        break\n",
    "    stop = stop + 1\n",
    "    if stop == 10:\n",
    "        break\n",
    "\n",
    "        \n",
    "        \n",
    "try:\n",
    "    element = WebDriverWait(driver, 5).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, 'div.paging > span > a'))\n",
    "    )\n",
    "except:\n",
    "    print('시작이 안 좋네')    \n",
    "page_url = driver.find_element_by_css_selector('div.paging > span > a').get_attribute('href')\n",
    "page_url = page_url[:-2]\n",
    "\n",
    "i = 1\n",
    "url_list = []\n",
    "stop_hard = 1\n",
    "justin = 1\n",
    "while True:\n",
    "    try:\n",
    "        \n",
    "        URL = page_url + str(10 * i - 9)\n",
    "        driver.get(URL)\n",
    "        try:\n",
    "            element = WebDriverWait(driver, 5).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, 'dt.text-inline'))\n",
    "            )\n",
    "        except:\n",
    "            # print('도저히 이 element를 못 찾네 ', str(10 * i - 9))\n",
    "            driver.refresh\n",
    "        \n",
    "        titles = driver.find_elements_by_css_selector('dt.text-inline')\n",
    "        dates = [day.text[-16:-6].replace('.', '') for day in driver.find_elements_by_css_selector('ul.search-list dl dd.text-inline span')]\n",
    "        # print(len(titles), ' ', URL)\n",
    "        \n",
    "        if len(titles) == 0:\n",
    "            raise # print('이 부분은 title이 0개', URL)\n",
    "            \n",
    "        for j in range(len(titles)):\n",
    "            url_list.append(titles[j].find_element_by_tag_name('a').get_attribute('href').replace('https://news.nate.com/view/', ''))\n",
    "            \n",
    "        if True:\n",
    "            print('\\r{}/13000'.format(i + justin * 100 - 100), end = '')\n",
    "            # print('진행상황 ({}/125000)'.format(i * justin * 10), 'url 개수 = %d' %(len(url_list)))\n",
    "            # pd.Series(url_list).to_csv('news_data/news{}.csv'.format(justin), index = False)\n",
    "            \n",
    " \n",
    "            \n",
    "        i = i + 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        # print(e)\n",
    "        # print('%d 번 페이지는 크롤링 못 함, refresh 필요' %i)\n",
    "        None\n",
    "\n",
    "    if i == 101:\n",
    "        print('끝났습니다. 정상적으로 크롤링되었습니다. %s' %date_input)\n",
    "        print('')\n",
    "        dates = {day for d in url_list for day in re.findall('([0-9]+)n', d)}\n",
    "        date_format = [datetime.strptime(dd, '%Y%m%d') for dd in dates]\n",
    "        date_input = min(date_format)\n",
    "        print(date_input)\n",
    "        start_date = date_input.strftime('%Y%m%d')\n",
    "        driver.find_element_by_name('ps1').clear()\n",
    "        driver.find_element_by_name('ps1').send_keys(finish_date)\n",
    "        driver.find_element_by_name('ps2').clear()\n",
    "        driver.find_element_by_name('ps2').send_keys(start_date)\n",
    "        time.sleep(0.5)\n",
    "        driver.find_element_by_class_name('type-search-btn').click()\n",
    "        time.sleep(5)        \n",
    "        while True:\n",
    "            try:\n",
    "                if driver.find_element_by_css_selector('div.none-result'):\n",
    "                    driver.find_element_by_name('ps1').clear()\n",
    "                    driver.find_element_by_name('ps1').send_keys(finish_date)\n",
    "                    driver.find_element_by_name('ps2').clear()\n",
    "                    driver.find_element_by_name('ps2').send_keys(start_date)\n",
    "                    time.sleep(0.5)\n",
    "                    driver.find_element_by_class_name('type-search-btn').click()\n",
    "                    time.sleep(3)\n",
    "            except:\n",
    "                # print('날짜 변경 시 오류 없음')\n",
    "                try:\n",
    "                    element = WebDriverWait(driver, 5).until(\n",
    "                        EC.presence_of_element_located((By.CSS_SELECTOR, 'div.paging > span > a'))\n",
    "                    )\n",
    "                    page_url = driver.find_element_by_css_selector('div.paging > span > a').get_attribute('href')\n",
    "                    page_url = page_url[:-2]\n",
    "                except:\n",
    "                    # print('실제로 날짜는 안 바뀜')\n",
    "                    None\n",
    "                break\n",
    "        url_list = []\n",
    "        i = 1\n",
    "        justin += 1\n",
    "        \n",
    "    stop_hard += 1\n",
    "    if stop_hard == 1000000 | justin == 130:\n",
    "        print('오류가 발생했습니다. 강제로 종류합니다.')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9429"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "path = 'news_data'\n",
    "url = 'https://news.nate.com/view/'\n",
    "\n",
    "all_files = glob.glob(path + '/*.csv')\n",
    "df_list = [pd.read_csv(file, encoding = 'utf-8', header = None) for file in all_files]\n",
    "df = pd.concat(df_list, sort = False)\n",
    "df.columns = ['URL']\n",
    "\n",
    "df.drop_duplicates('URL', keep = 'first', inplace = True)\n",
    "url_list = set(df['URL'].values)\n",
    "len(url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "\n",
    "title = []\n",
    "content = []\n",
    "title = []\n",
    "reporter = []\n",
    "date = []\n",
    "\n",
    "for u in url_list:\n",
    "    driver.get(url + u)\n",
    "    title.append(driver.find_element_by_css_selector('#articleView h3').text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 새로 배운 사실\n",
    "1. try except은 혁명이다.\n",
    "2. 크롤링을 못 하도록 수법을 걸어놨는데, iframe페이지로 들어가니 상관 없어짐"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
