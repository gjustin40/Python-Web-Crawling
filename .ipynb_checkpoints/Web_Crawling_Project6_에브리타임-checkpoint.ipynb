{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Web Crawling Prject 6\n",
    "## '대학교 커뮤니티 사이트 '에브리타임' 크롤링'\n",
    "- 대학교 커뮤니티 사이트인 '에브리타임'의 게시판에 있는 글을 크롤링\n",
    "- 분석을 위해 자유게시판의 text data 수집\n",
    "- Crawling 모듈로는 Selenium을 이용한다.\n",
    "- Webdriver는 Chrome을 이용한다.\n",
    "## 방법\n",
    "\n",
    "1. 에브리타임에 접속\n",
    "2. 로그인 및 자유게시판 접속\n",
    "3. 매 페이지마다 있는 게시글 크롤링\n",
    "4. 제목, 내용, 추천 수, 댓글 수, 시간, URL 등을 수집\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 각 게시글 접속\n",
    "1. 각 게시글에 입장할 때 click을 통해 입장\n",
    "2. 각 게시글에 입장할 때 해당 게시글의 url을 통해 입장 << 이 방법 채택<br>\n",
    "(이유 : click을 이용하기 위해서는 window창을 각 게시글로 이동시켜줘야 함, scrolled into view, 번거로움)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time as t\n",
    "\n",
    "\n",
    "options = webdriver.Chromeoptions()\n",
    "options.add_argument('headless') \n",
    "options.add_argument('window-size = 1920x1980')\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "\n",
    "driver.get('https://everytime.kr')\n",
    "\n",
    "driver.find_element_by_class_name('login').find_element_by_link_text('로그인').click()\n",
    "\n",
    "driver.find_element_by_name('userid').send_keys('-------')\n",
    "driver.find_element_by_name('password').send_keys('--------')\n",
    "\n",
    "driver.find_element_by_class_name('submit').click()\n",
    "\n",
    "driver.find_element_by_link_text('자유게시판').click()\n",
    "driver.refresh()\n",
    "url = []\n",
    "time = []\n",
    "title = []\n",
    "content = []\n",
    "vote = []\n",
    "comment = []\n",
    "n = 0\n",
    "for page_number in range(1,501,1):\n",
    "    page_url = driver.current_url\n",
    "    driver.implicitly_wait(3)\n",
    "    driver.execute_script('window.scrollTo(0,document.body.scrollHeight);')\n",
    "    driver.execute_script('window.scrollTo(0,0);')\n",
    "    post_list = driver.find_elements_by_tag_name('article')\n",
    "    \n",
    "    for i in range(20):         \n",
    "        \n",
    "        \n",
    "        post_url = post_list[i].find_element_by_tag_name('a').get_attribute('href')\n",
    "        \n",
    "        #post_list[i].click()\n",
    "        #url.append(driver.current_url)\n",
    "        url.append(post_url)\n",
    "        time.append(driver.find_element_by_tag_name('time').get_attribute('title'))\n",
    "        \n",
    "        driver.get(post_url)\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html5lib')\n",
    "        print('start')\n",
    "        title.append(soup.select('h2.large')[0].text.strip())\n",
    "        print(i)\n",
    "        content.append(soup.select('p.large')[0].text.strip())\n",
    "        vote.append(soup.select('li.vote')[0].text.strip())\n",
    "        comment.append(soup.select('li.comment')[0].text.strip())\n",
    "        driver.back()\n",
    "        \n",
    "    if page_number % 50 == 0:\n",
    "        df = pd.DataFrame({'title' : title, 'content' : content, 'vote' : vote, 'comment' : comment, 'url' : url, 'time' : time})\n",
    "        df = df[['title', 'content', 'comment', 'vote', 'time', 'url']]\n",
    "        df.to_csv('everytime{}.csv'.format(page_number // 50))\n",
    "        url = []\n",
    "        time = []\n",
    "        title = []\n",
    "        content = []\n",
    "        vote = []\n",
    "        comment = []\n",
    "    driver.implicitly_wait(20)\n",
    "    driver.execute_script('window.scrollTo(0,document.body.scrollHeight);')\n",
    "    driver.find_element_by_css_selector('a.next').click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BeautifulSoup 파싱 없이 바로\n",
    "- driver에서 element로 바로 찾아서 append\n",
    "- 파싱으로 인해 페이지의 로드 시간이 소요되어 가끔 뒤에 코드가 먼저 실행되는 문제 해결\n",
    "- 시간 단축\n",
    "\n",
    "###  추가사항\n",
    "- 속도 개선을 위해 절대적 대기(sleep) -> 명시적 대기(explicit wait)로 변경\n",
    "- 속도 개선을 위해 chrome driver의 이미지 출력 옵션을 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time as t\n",
    "\n",
    "# 명시적 대기\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('headless')\n",
    "options.add_argument('window-size = 1920x1980')\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "\n",
    "driver.get('https://everytime.kr')\n",
    "\n",
    "driver.find_element_by_class_name('login').find_element_by_link_text('로그인').click()\n",
    "\n",
    "driver.find_element_by_name('userid').send_keys('------------')\n",
    "driver.find_element_by_name('password').send_keys('------------')\n",
    "\n",
    "driver.find_element_by_class_name('submit').click()\n",
    "\n",
    "driver.find_element_by_link_text('자유게시판').click()\n",
    "driver.refresh()\n",
    "\n",
    "url = []\n",
    "time = []\n",
    "title = []\n",
    "content = []\n",
    "vote = []\n",
    "comment = []\n",
    "n = 0\n",
    "\n",
    "#for page_number in range(1,501,1):\n",
    "for page_number in range(2):\n",
    "    page_url = driver.current_url\n",
    "\n",
    "    driver.execute_script('window.scrollTo(0,document.body.scrollHeight);')\n",
    "    driver.execute_script('window.scrollTo(0,0);')\n",
    "    t.sleep(1)\n",
    "    post_url_list = [u.get_attribute('href') for u in driver.find_elements_by_css_selector('article a.article')]\n",
    "    for i in range(3):\n",
    "        #post_list = driver.find_elements_by_tag_name('article')\n",
    "        #post_url = post_list[i].find_element_by_tag_name('a').get_attribute('href')\n",
    "        post_url = post_url_list[i]\n",
    "        #post_list[i].click()\n",
    "        driver.get(post_url)\n",
    "        \n",
    "        t.sleep(2)\n",
    "        url.append(post_url)\n",
    "        time.append(driver.find_element_by_tag_name('time').get_attribute('title'))\n",
    "\n",
    "\n",
    "        # method1\n",
    "        title.append(driver.find_element_by_css_selector('article a.article h2.large').text)\n",
    "\n",
    "        content.append(driver.find_element_by_css_selector('article a.article p.large').text.strip())\n",
    "        vote.append(driver.find_element_by_css_selector('article a.article ul.status li.vote').text)\n",
    "        comment.append(driver.find_element_by_css_selector('article a.article ul.status li.comment').text)\n",
    "\n",
    "        driver.back()\n",
    "        \n",
    "    if page_number % 50 == 0:\n",
    "        df = pd.DataFrame({'title' : title, 'content' : content, 'vote' : vote, 'comment' : comment, 'url' : url, 'time' : time})\n",
    "        df = df[['title', 'content', 'comment', 'vote', 'time', 'url']]\n",
    "        df.to_csv('everytime_data/everytime{}.csv'.format(page_number))\n",
    "        print(page_number)\n",
    "        title, content, vote, comment, url, time = [], [], [], [], [], []\n",
    "    driver.execute_script('window.scrollTo(0,document.body.scrollHeight);')\n",
    "    t.sleep(2)\n",
    "    driver.find_element_by_css_selector('a.next').click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 중간부터 시작\n",
    "- 여러 이유로 반복문이 중단되었을 때 이용\n",
    "- 마지막 page number을 입력해서 해당 페이지부터 재시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time as t\n",
    "\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('headless')\n",
    "options.add_argument('window-size = 1920x1980')\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "\n",
    "driver.get('https://everytime.kr')\n",
    "\n",
    "driver.find_element_by_class_name('login').find_element_by_link_text('로그인').click()\n",
    "\n",
    "driver.find_element_by_name('userid').send_keys('-----------')\n",
    "driver.find_element_by_name('password').send_keys('-------------')\n",
    "\n",
    "driver.find_element_by_class_name('submit').click()\n",
    "\n",
    "page_n = 46 # The page number to start\n",
    "driver.get('https://everytime.kr/377390/p/' + str(page_n))\n",
    "\n",
    "url = []\n",
    "time = []\n",
    "title = []\n",
    "content = []\n",
    "vote = []\n",
    "comment = []\n",
    "n = 0\n",
    "\n",
    "for page_number in range(page_n,2062,1):\n",
    "    \n",
    "    page_url = driver.current_url\n",
    "\n",
    "    driver.execute_script('window.scrollTo(0,document.body.scrollHeight);')\n",
    "    driver.execute_script('window.scrollTo(0,0);')\n",
    "    t.sleep(1)\n",
    "    post_url_list = [u.get_attribute('href') for u in driver.find_elements_by_css_selector('article a.article')]\n",
    "    for i in range(20):\n",
    "        #post_list = driver.find_elements_by_tag_name('article')\n",
    "        #post_url = post_list[i].find_element_by_tag_name('a').get_attribute('href')\n",
    "        post_url = post_url_list[i]\n",
    "        #post_list[i].click()\n",
    "        driver.get(post_url)\n",
    "        \n",
    "        t.sleep(2)\n",
    "        url.append(post_url)\n",
    "        time.append(driver.find_element_by_tag_name('time').get_attribute('title'))\n",
    "\n",
    "\n",
    "        # method1\n",
    "        title.append(driver.find_element_by_css_selector('article a.article h2.large').text)\n",
    "\n",
    "        content.append(driver.find_element_by_css_selector('article a.article p.large').text.strip())\n",
    "        vote.append(driver.find_element_by_css_selector('article a.article ul.status li.vote').text)\n",
    "        comment.append(driver.find_element_by_css_selector('article a.article ul.status li.comment').text)\n",
    "\n",
    "        driver.back()\n",
    "        \n",
    "    if page_number % 50 == 0:\n",
    "        df = pd.DataFrame({'title' : title, 'content' : content, 'vote' : vote, 'comment' : comment, 'url' : url, 'time' : time})\n",
    "        df = df[['title', 'content', 'comment', 'vote', 'time', 'url']]\n",
    "        df.to_csv('everytime_data/everytime{}.csv'.format(page_number))\n",
    "        print(page_number)\n",
    "        title, content, vote, comment, url, time = [], [], [], [], [], []\n",
    "    driver.execute_script('window.scrollTo(0,document.body.scrollHeight);')\n",
    "    t.sleep(2)\n",
    "    driver.find_element_by_css_selector('a.next').click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat csv files\n",
    "- 50page마다 저장했던 크롤링 데이터를 concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4692 entries, 0 to 4691\n",
      "Data columns (total 6 columns):\n",
      "title      4692 non-null object\n",
      "content    4692 non-null object\n",
      "comment    4692 non-null int64\n",
      "vote       4692 non-null int64\n",
      "time       4692 non-null object\n",
      "url        4692 non-null object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 220.0+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>comment</th>\n",
       "      <th>vote</th>\n",
       "      <th>time</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>지하철에서 뭐 좀 쳐먹지마 제발</td>\n",
       "      <td>냄새 역겨워</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-11-01 12:56:28</td>\n",
       "      <td>https://everytime.kr/377390/v/56050760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>계절학기 수요 조사 신청 좀 도와주세요ㅠㅠ</td>\n",
       "      <td>중선인 교양이라 주관학과가 대양휴머니티칼리지인데요ㅠㅠㅠ 학교 홈페이지에 치니까 행정...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-11-01 12:55:30</td>\n",
       "      <td>https://everytime.kr/377390/v/56050712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>눈떠보니</td>\n",
       "      <td>11정거장이나 지나있네?</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-11-01 12:11:09</td>\n",
       "      <td>https://everytime.kr/377390/v/56048337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>휴게실에서 소리틀어놓고 스포츠중계보는건 뭐하자는거지</td>\n",
       "      <td>딴엔 소리 작게 틀어놨다고 생각하는모양인데 ㅋㅋ;</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-11-01 11:47:51</td>\n",
       "      <td>https://everytime.kr/377390/v/56046985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>와 방금기상</td>\n",
       "      <td>오늘 1교시부터 풀수업인데...\\r\\r\\r\\r\\r\\r\\r\\r\\n이참에 오늘은 자체휴강이다</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-11-01 11:44:22</td>\n",
       "      <td>https://everytime.kr/377390/v/56046827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          title  \\\n",
       "0             지하철에서 뭐 좀 쳐먹지마 제발   \n",
       "1       계절학기 수요 조사 신청 좀 도와주세요ㅠㅠ   \n",
       "2                          눈떠보니   \n",
       "3  휴게실에서 소리틀어놓고 스포츠중계보는건 뭐하자는거지   \n",
       "4                        와 방금기상   \n",
       "\n",
       "                                             content  comment  vote  \\\n",
       "0                                             냄새 역겨워       16     0   \n",
       "1  중선인 교양이라 주관학과가 대양휴머니티칼리지인데요ㅠㅠㅠ 학교 홈페이지에 치니까 행정...        0     0   \n",
       "2                                      11정거장이나 지나있네?        8     0   \n",
       "3                        딴엔 소리 작게 틀어놨다고 생각하는모양인데 ㅋㅋ;        4     1   \n",
       "4  오늘 1교시부터 풀수업인데...\\r\\r\\r\\r\\r\\r\\r\\r\\n이참에 오늘은 자체휴강이다        5     1   \n",
       "\n",
       "                  time                                     url  \n",
       "0  2018-11-01 12:56:28  https://everytime.kr/377390/v/56050760  \n",
       "1  2018-11-01 12:55:30  https://everytime.kr/377390/v/56050712  \n",
       "2  2018-11-01 12:11:09  https://everytime.kr/377390/v/56048337  \n",
       "3  2018-11-01 11:47:51  https://everytime.kr/377390/v/56046985  \n",
       "4  2018-11-01 11:44:22  https://everytime.kr/377390/v/56046827  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "path = 'everytime_data/clean_data'\n",
    "all_files = glob.glob(path + '/*.csv')\n",
    "\n",
    "df_list = [pd.read_csv(file, encoding = 'utf-8', index_col = None) for file in all_files]\n",
    "df = pd.concat(df_list)\n",
    "\n",
    "df.drop_duplicates('title', keep = 'first', inplace = True)\n",
    "df.reset_index(drop = True, inplace = True)\n",
    "df = df[['title', 'content', 'comment', 'vote', 'time', 'url']]\n",
    "\n",
    "df.to_csv('everytime_data/clean_data/everytime.csv', encoding = 'utf-8')\n",
    "print(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 분석하고자 하는 것\n",
    "1. 단어 빈도 수 - 시각화\n",
    "2. 단어 유사도\n",
    "2. 주제별로 클러스터링\n",
    "3. 시기별 이용 빈도\n",
    "4. 시기별 주제\n",
    "5. 주로 틀리는 맞춤법\n",
    "6. 키워드별 감성분석"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
