{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Crawling Project 2\n",
    "## '뉴스 기사 크롤링하기'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# naver 뉴스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "\n",
    "driver.get('http://naver.com')\n",
    "\n",
    "driver.find_element_by_id('query').send_keys('동성제약')\n",
    "driver.find_element_by_id('search_btn').click()\n",
    "\n",
    "driver.find_element_by_css_selector('div.lnb_menu').find_element_by_link_text(\n",
    "    '뉴스').click()\n",
    "\n",
    "driver.find_element_by_id('_search_option_btn').click()\n",
    "menu = driver.find_elements_by_css_selector('ul.option_menu > li.menu')\n",
    "menu[2].click()\n",
    "menu[2].find_element_by_link_text('제목').click()\n",
    "\n",
    "current_window = driver.current_window_handle\n",
    "\n",
    "data = {'title': [], 'date': [], 'company': [], 'context': [], 'reporter': []}\n",
    "for i in range(50):\n",
    "    for naver_news in driver.find_elements_by_link_text('네이버뉴스'):\n",
    "        naver_news.click()\n",
    "        driver.switch_to.window(driver.window_handles[1])\n",
    "        html = driver.page_source\n",
    "        soup = bs(html, 'html.parser')\n",
    "        data['title'].append(soup.select('h3.tts_head')[0].text.strip())\n",
    "        data['date'].append(soup.select('span.t11')[0].text.strip())\n",
    "        soup.find('div', id='articleBodyContents').script.extract()\n",
    "        data['context'].append(\n",
    "            soup.find('div', id='articleBodyContents').text.strip())\n",
    "        driver.close()\n",
    "        driver.switch_to.window(current_window)\n",
    "    driver.find_element_by_link_text('다음페이지').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    for naver_news in driver.find_elements_by_link_text('네이버뉴스'):\n",
    "        naver_news.click()\n",
    "        driver.switch_to.window(driver.window_handles[1])\n",
    "        html = driver.page_source\n",
    "        soup = bs(html, 'html.parser')\n",
    "        data['title'].append(soup.select('h3.tts_head')[0].text.strip())\n",
    "        data['date'].append(soup.select('span.t11')[0].text.strip())\n",
    "        soup.find('div', id='articleBodyContents').script.extract()\n",
    "        data['context'].append(\n",
    "            soup.find('div', id='articleBodyContents').text.strip())\n",
    "        driver.close()\n",
    "        driver.switch_to.window(current_window)\n",
    "    driver.find_element_by_link_text('다음페이지').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.switch_to.window(current_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 36min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for i in range(120):    \n",
    "    for naver_news in driver.find_elements_by_link_text('네이버뉴스'):\n",
    "        naver_news.click()\n",
    "        driver.switch_to.window(driver.window_handles[1])\n",
    "        html = driver.page_source\n",
    "        soup = bs(html, 'html.parser')\n",
    "        if len(soup.select('h3.tts_head')) == 0:\n",
    "            driver.close()\n",
    "            driver.switch_to.window(current_window)\n",
    "            break\n",
    "        data['title'].append(soup.select('h3.tts_head')[0].text.strip())\n",
    "        data['date'].append(soup.select('span.t11')[0].text.strip())\n",
    "        soup.find('div', id = 'articleBodyContents').script.extract()\n",
    "        data['context'].append(soup.find('div', id = 'articleBodyContents').text.strip())\n",
    "        driver.close()\n",
    "        driver.switch_to.window(current_window)\n",
    "    driver.find_element_by_link_text('다음페이지').click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=103&oid=022&aid=0002671699\n",
    "\n",
    "이 놈에서 자꾸 오류가 발생하는데.... 뭔지를 모르겟다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 발생한 오류\n",
    "### 1. 인터넷 뉴스 회사마다 html형식이 달라 크롤링에 제약이 생겼다.\n",
    " - 해결 못 함\n",
    "\n",
    "### 2. pd.read_csv() 과정에서 'Initializing from file failed' 오류가 발생\n",
    " - pandas의 자체 버그이며 해결방법으로는 engine = 'python' 옵션을 추가해주면 된다.\n",
    " \n",
    "### 3. for구문 중간에 자꾸 list Index out of range 오류가 발생\n",
    " - 이거는 단지 select된 element내에 아무것도 없었기 때문에 [0]에서 오류가 발생\n",
    " - if구문을 통해 조건을 걸어 무시할 수 있도록 조치함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 새로 배운 것\n",
    "### 1. Multiple class인 element 찾기\n",
    " - css_selector(.class.class)\n",
    "\n",
    "### 2. BeautifulSoup를 통해 parsing된 문서에서 id로 찾기(select 말고)\n",
    " - soup.find('tag', id = '')\n",
    " - 참고https://stackoverflow.com/questions/25614702/get-contents-of-div-by-id-with-beautifulsoup\n",
    " \n",
    "### 3. 글 중간에 있는 특정 tag를 제외한 상태로 긁어오기\n",
    " - soup.find().tag.extract() : tag를 extract()한 상태가 된다.(soup 안에서 해당 tag가 삭제됨)\n",
    " - 참고https://stackoverflow.com/questions/48877343/exclude-tags-with-beautifulsoup\n",
    " - 제외한다는 말을 'exclude'라고 표현함\n",
    " \n",
    "### 4. DataFrame 내에 중복되는 row 삭제하기\n",
    " - pd.drop_duplicates(column_label, keep = 'first')\n",
    " - https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop_duplicates.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
